{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b784b50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 22:05:56.512 python[25268:43390430] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-02-05 22:05:56.512 python[25268:43390430] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tracker import *\n",
    "import centroidtracker as cent\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "tracker = cent.CentroidTracker(maxDisappeared=150, maxDistance=60)\n",
    "\n",
    "# Reading Video into Python \n",
    "cap = cv2.VideoCapture('/Users/gideonowusu/Downloads/PhD 2028/Projects/ML-Melanoma/GitHub/Zoomed_In.avi')\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define codec and create VideoWriter object\n",
    "out = cv2.VideoWriter('/Users/gideonowusu/Downloads/PhD 2028/Projects/ML-Melanoma/GitHub/Melanoma Output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "\n",
    "# Object detection from Stable camera\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=40)\n",
    "\n",
    "# Function to calculate Euclidean distance between two points\n",
    "def calculate_distance(point1, point2):\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "objects = {}   \n",
    "maximum_inactive_frames = 2\n",
    "next_id = 0\n",
    "some_threshold = 55\n",
    "line_x = 0\n",
    "max_inactive_frames = 40\n",
    "inactive_frames = {}\n",
    "trajectory_dict = {}\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Preprocessing\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Object Detection\n",
    "    mask = object_detector.apply(blurred)\n",
    "    _, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    detections = []\n",
    "    merged_boxes = []\n",
    "    \n",
    "    # Process contours\n",
    "    for cnt in contours:\n",
    "        contour_area = cv2.contourArea(cnt)\n",
    "        if 13 < contour_area < 1000:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            centroid = (int(x + w / 2), int(y + h / 2))\n",
    "\n",
    "            existing_track = None\n",
    "            for obj_id, bbox in objects.items():\n",
    "                if calculate_distance(centroid, (bbox[0] + bbox[2] / 2, bbox[1] + bbox[3] / 2)) < some_threshold:\n",
    "                    existing_track = obj_id\n",
    "                    break\n",
    "\n",
    "            if existing_track is not None:\n",
    "                objects[existing_track] = (x, y, w, h)\n",
    "                inactive_frames[existing_track] = 0\n",
    "            else:\n",
    "                objects[next_id] = (x, y, w, h)\n",
    "                inactive_frames[next_id] = 0\n",
    "                next_id += 1\n",
    "            \n",
    "            merged = False\n",
    "            for box in merged_boxes:\n",
    "                bx, by, bw, bh = box\n",
    "                if (x >= bx and x <= bx + bw) or (bx >= x and bx <= x + w):\n",
    "                    if (y >= by and y <= by + bh) or (by >= y and by <= y + h):\n",
    "                        merged = True\n",
    "                        merged_boxes.remove(box)\n",
    "                        xmin = min(x, bx)\n",
    "                        ymin = min(y, by)\n",
    "                        xmax = max(x + w, bx + bw)\n",
    "                        ymax = max(y + h, by + bh)\n",
    "                        merged_boxes.append((xmin, ymin, xmax - xmin, ymax - ymin))\n",
    "                        break\n",
    "            \n",
    "            if not merged:\n",
    "                merged_boxes.append((x, y, w, h))\n",
    "    \n",
    "    # Draw merged bounding boxes\n",
    "    for box in merged_boxes:\n",
    "        x, y, w, h = box\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "    \n",
    "    objects = tracker.update(detections)\n",
    "    for (objectId, bbox) in objects.items():\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        cX = int((x1 + x1 + x2) // 2.0)\n",
    "        cY = int((y1 + y1 + y2) // 2.0)\n",
    "    \n",
    "        if objectId not in trajectory_dict:\n",
    "            trajectory_dict[objectId] = [(cX, cY)]\n",
    "        else:\n",
    "            trajectory_dict[objectId].append((cX, cY))\n",
    "    \n",
    "        text = \"ID:{}\".format(objectId)\n",
    "        cv2.putText(frame, text, (x1, y1 - 5), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 1)\n",
    "        cv2.line(frame, (line_x, 950), (line_x, 10), (0, 255, 0), thickness=1)\n",
    "    \n",
    "    # Write frame to output video\n",
    "    out.write(frame)\n",
    "    \n",
    "    # Remove inactive tracks\n",
    "    inactive_tracks = [obj_id for obj_id, inactive_frame_count in inactive_frames.items() if inactive_frame_count >= max_inactive_frames]\n",
    "    for obj_id in inactive_tracks:\n",
    "        del objects[obj_id]\n",
    "        del inactive_frames[obj_id]\n",
    "\n",
    "    for obj_id in objects.keys():\n",
    "        inactive_frames[obj_id] += 1\n",
    "    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    key = cv2.waitKey(30)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "# Release video writer\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f07b77c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
